{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pset4_6_869_sp22.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPyxgwfCtkBH"
      },
      "source": [
        "# Neural Net Inference and Perturbations\n",
        "\n",
        "\n",
        "Part of this code is based on Alexander Madry's lab robustness applications toolkit and Google Deepdream. You can check more in https://github.com/MadryLab\n",
        "and https://distill.pub/2017/feature-visualization/\n",
        "\n",
        "\n",
        "**Note:** To speed up the execution of the experiments we recommend using GPU acceleration. If you run this in Colab, simply do:\n",
        "\n",
        "Runtime > Change Runtime type > Hardware accelerator > Gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQpJ32lb6MmD"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "cuda_available = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlg48zONYlLy"
      },
      "source": [
        "import requests\n",
        "def download(url, fn=None):\n",
        "  if fn is None:\n",
        "    fn = url.split('/')[-1]\n",
        "  r = requests.get(url)\n",
        "  if r.status_code == 200:\n",
        "      open(fn, 'wb').write(r.content)\n",
        "      print(\"{} downloaded: {:.2f} KB\".format(fn, len(r.content)/1024.))\n",
        "  else:\n",
        "      print(\"url not found:\", url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7p15MZAUU7c"
      },
      "source": [
        "Download the test image and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zK12DvgLzrz"
      },
      "source": [
        "download('http://6.869.csail.mit.edu/fa19/psets19/pset6/imagenet_classes.txt')\n",
        "download('http://6.869.csail.mit.edu/fa19/psets19/pset6/WelshCorgi.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSWy3KeHY7Vj"
      },
      "source": [
        "# Inference in a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_hXG7PpZItx"
      },
      "source": [
        "In this exercise, you will be playing with a convolutional network to classify images into semantic labels. You will be working with ResNet50, a variant of the residual convolutional network architecture. We will be testing the network to classify images into the 1000 imagenet categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt5j4rILakPs"
      },
      "source": [
        "### Load imagenet class names\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8S1KHKKaurC"
      },
      "source": [
        "with open('imagenet_classes.txt', 'r') as f:\n",
        "  imagenet_classes = f.readlines()\n",
        "  imagenet_classes_short = [x.strip().split(',')[-1] for x in imagenet_classes]\n",
        " \n",
        "print('Imagenet classes')\n",
        "for it, class_name in enumerate(imagenet_classes):\n",
        "  if it == 3:\n",
        "    print('...')\n",
        "  elif it < 4 or it > 997:\n",
        "    print('{}. {}'.format(it, class_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf0tJQ3kZzkx"
      },
      "source": [
        "## Running a randomly initialized network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3OppKjUbhMw"
      },
      "source": [
        "We will start by using a randomly initalized network to perform classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDy2nbxgdLpx"
      },
      "source": [
        "# Download ResNet50 from Pytorch repository\n",
        "arch = 'resnet50'\n",
        "model = models.__dict__[arch]()\n",
        "# We set it in eval, so that batch normalization layers are not updated\n",
        "model.eval();\n",
        "if cuda_available:\n",
        "  model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqSZRVUJVjAb"
      },
      "source": [
        "# Visualize the last layer\n",
        "model.fc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "635O0bKbb2km"
      },
      "source": [
        "# Load the image we will be playing with\n",
        "img = cv2.imread('WelshCorgi.jpeg')\n",
        "plt.imshow(img[:, :, ::-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DskLmy8cINu"
      },
      "source": [
        "### Preparing the image for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPvNDdZh6Q56"
      },
      "source": [
        "# In order to run the image through a model. We need to prepare it first\n",
        "# This includes:\n",
        "# 1. Resizing the image to an appropiate size for the network\n",
        "# 2. Convert the image to a tensor - this will set the image in the 0-1 range\n",
        "#    and change the channel/dimensions order\n",
        "# 3. Normalize the image\n",
        "# 4. Put the image in a batch. In our case we will use a single element batch.\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "def prepare_image(image_cv2, do_normalize=True):\n",
        "  # Resize\n",
        "  img = cv2.resize(image_cv2, (224, 224))\n",
        "  img = img[:, :, ::-1].copy()\n",
        "  # Convert to tensor\n",
        "  tensor_img = transforms.functional.to_tensor(img)\n",
        "  \n",
        "  # Possibly normalize\n",
        "  if do_normalize:\n",
        "    tensor_img = normalize(tensor_img)\n",
        "  # Put image in a batch\n",
        "  batch_tensor_img = torch.unsqueeze(tensor_img, 0)\n",
        "  \n",
        "  # Put the image in the gpu\n",
        "  if cuda_available:\n",
        "    batch_tensor_img = batch_tensor_img.cuda()\n",
        "  return batch_tensor_img\n",
        "\n",
        "\n",
        "def UnNormalize(mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]):\n",
        "  std_arr = torch.tensor(std)[:, None, None]\n",
        "  mean_arr = torch.tensor(mean)[:, None, None]\n",
        "  def func(img):\n",
        "    img = img.clone()\n",
        "    img *= std_arr\n",
        "    img += mean_arr\n",
        "    return img\n",
        "  return func\n",
        "unnormalize = UnNormalize()\n",
        "\n",
        "def obtain_image(tensor_img, do_normalize=True):\n",
        "  tensor_img = tensor_img.cpu()\n",
        "  if do_normalize:\n",
        "    tensor_img = unnormalize(tensor_img)\n",
        "  img = transforms.functional.to_pil_image((tensor_img.data))\n",
        "  return img\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRYoMgRZdR6f"
      },
      "source": [
        "### Running the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2GdV2Vyek9V"
      },
      "source": [
        "This architecture outputs a vector of 1000 elements, that correspond to the class logits: each of the class probabilities before doing a softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzANMajcdHje"
      },
      "source": [
        "# Prepare the image\n",
        "batch_normalized_img = prepare_image(img)\n",
        "# Run it through the network\n",
        "output = model(batch_normalized_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWB5WZM8e7Ty"
      },
      "source": [
        "Let's visualize the top classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sErC9LuC7mEt"
      },
      "source": [
        "def plot_top_classes(values, top_k=5):\n",
        "  sorted_classes = np.argsort(-values)\n",
        "  class_ids = sorted_classes[:top_k]\n",
        "  class_names = [imagenet_classes_short[it] for it in list(class_ids)]\n",
        "  class_values = values[class_ids]\n",
        "  plt.bar(class_names, class_values)\n",
        "  plt.xticks(rotation=60)\n",
        "\n",
        "\n",
        "plot_top_classes(output[0,:].data.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eOrQ4Hhfyc4"
      },
      "source": [
        "Unsurprisingly, the network predictions have nothing to do with the image, since the network was intialized from scratch. Instead, we will load the network with the weights after training a classifier on the imagenet dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYLm9NKRgWNp"
      },
      "source": [
        "arch = 'resnet50'\n",
        "model = models.__dict__[arch](pretrained=True)\n",
        "model.eval();\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sni0vPs2MCp0"
      },
      "source": [
        "output = model(batch_normalized_img.cuda())\n",
        "plot_top_classes(output[0,:].data.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxuPDY7Zgvgr"
      },
      "source": [
        "The top predictions seem to have much more sense now. But it is not clear what the scalar in the plot means. Complete the code below to normalize the logits to the probability, using the `torch.nn.functional.softmax` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KetuX0vmPayI"
      },
      "source": [
        "def output2prob(output):\n",
        "  ### TODO1\n",
        "  # Your code here:\n",
        "  prob = \n",
        "  ###\n",
        "  return prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WktEvr48hbrm"
      },
      "source": [
        "output = model(batch_normalized_img.cuda())\n",
        "prob = output2prob(output)\n",
        "plot_top_classes(prob[0,:].data.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIxm5IhVdN_e"
      },
      "source": [
        "## Adversarial Examples\n",
        "Although the above results show that deep neural networks can classify the image correctly as *corgi*, it is actually not robust! In this section, we are going to show that the neural networks can be \"fooled\" when some unperceivable noises are added to the image.\n",
        "\n",
        "Here's an example:\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/4000/1*PmCgcjO3sr3CPPaCpy5Fgw.png\" alt=\"drawing\" width=\"600\"/>\n",
        "\n",
        "Note that the left and right images look the same to the human eyes, but result in very different neural network predictions. Since the right image can pose security threat to our model, we call these images **adversarial examples**.\n",
        "\n",
        "How can we create adversarial examples? Remember that when training a neural network, we use backpropagation to obtain the gradient of the loss with respect to the network parameters, and use it to update the the parameters that minimize the loss. \n",
        "\n",
        "We can also use backpropagation to obtain the gradient of the loss with respect to the input image, given the network parameters. If we update the image according to that gradient, we can generate images that maximize certain activations, or minimize the loss. If properly applied, small changes in image can completely change the neural network's prediction and result in adversarial examples.\n",
        "\n",
        "\n",
        "\n",
        "Let's try to fool the neural network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-qcMwfDVgPC"
      },
      "source": [
        "### Attack the model\n",
        "We will use the following function to generate the adversarial examples. This function will take as input 1) the neural network model and 2) the normal image and output an adversarial example, a modified image that looks similar to the normal image but fool the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdfeLpFmTvwq"
      },
      "source": [
        "def generate_adversarial_example(model_fn, x, class_id, n_iter=200):\n",
        "  \"\"\"\n",
        "  :param model_fn: a callable that takes an input tensor and returns the model logits.\n",
        "  :param x: input tensor.\n",
        "  :param class_id: the id of the target class.\n",
        "  :return: a tensor for the adversarial example\n",
        "  \"\"\"\n",
        "  for i in tqdm(range(n_iter)):\n",
        "    ### TODO2\n",
        "    # You should:\n",
        "    # 1. Run the model with batch_tensor\n",
        "    # 2. Describe the loss or the objective you want to maximize\n",
        "    # 3. Compute the gradient of the objective with respect to the image\n",
        "    # using torch.autograd.grad\n",
        "    # - \n",
        "    # Your code here:\n",
        "    logit = \n",
        "    loss = \n",
        "    gradient = \n",
        "    ###\n",
        "    x = step.step(x, -1*gradient)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-tUmye5T2-0"
      },
      "source": [
        "### Step class\n",
        "We will use the following class to generate our image. This class will take a tensor x corresponding to the image a g corresponding to the gradient and will update x according to g. To ensure that the updated image lies in a reasonable manifold, we will also allow for a projection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JvM_cZJvrfm"
      },
      "source": [
        "class StepImage():\n",
        "  def __init__(self, orig_input, step_size=2, is_normalized=True, \n",
        "               renorm=True, eps=30, norm_update='l2'):\n",
        "    self.orig_input = orig_input\n",
        "    if is_normalized:\n",
        "      mean=[0.485, 0.456, 0.406]\n",
        "      std= [0.229, 0.224, 0.225]\n",
        "    else:\n",
        "      mean=[0., 0., 0.]\n",
        "      std= [1., 1., 1.]\n",
        "    \n",
        "    is_cuda = orig_input.is_cuda\n",
        "    self.mean = torch.tensor(mean)[:, None, None]\n",
        "    self.std = torch.tensor(std)[:, None, None]\n",
        "    if is_cuda:\n",
        "      self.mean = self.mean.cuda()\n",
        "      self.std = self.std.cuda()\n",
        "    self.eps = eps\n",
        "    self.renorm = renorm\n",
        "    self.step_size = step_size\n",
        "    self.norm_update = norm_update\n",
        "    \n",
        "  def project(self, x):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    diff = x - self.orig_input\n",
        "    if self.renorm:\n",
        "      diff = diff.renorm(p=2, dim=0, maxnorm=self.eps)\n",
        "    val_projected = self.orig_input + diff\n",
        "    \n",
        "    val_projected *= self.std\n",
        "    val_projected += self.mean\n",
        "    val_clamped = torch.clamp(val_projected, 0, 1)\n",
        "    val_clamped -= self.mean\n",
        "    val_clamped /= self.std\n",
        "    return val_clamped\n",
        "  \n",
        "  def step(self, x, g):\n",
        "    step_size = self.step_size\n",
        "    # Scale g so that each element of the batch is at least norm 1\n",
        "    if self.norm_update == 'l2':\n",
        "      l = len(x.shape) - 1\n",
        "      g_norm = torch.norm(g.view(g.shape[0], -1), dim=1).view(-1, *([1]*l))\n",
        "    else:\n",
        "      g_norm = torch.torch.abs(g).mean()\n",
        "    scaled_g = g / (g_norm + 1e-10)\n",
        "    stepped = x + scaled_g * step_size\n",
        "    projected = self.project(stepped)\n",
        "    return projected"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jiLAg_cwedQ"
      },
      "source": [
        "### Attack 1\n",
        "\n",
        "We will now update the image to make the model think this image is a **Tarantula (id 76)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVcd6T4kNPTZ"
      },
      "source": [
        "img = cv2.imread('WelshCorgi.jpeg')\n",
        "starting_image = prepare_image(img)\n",
        "\n",
        "# This allows to backpropagate the image\n",
        "batch_tensor = starting_image.clone().requires_grad_(True)\n",
        "\n",
        "# This updates the image according to some gradient\n",
        "step = StepImage(starting_image, step_size=3, renorm=True)\n",
        "batch_tensor = generate_adversarial_example(model, batch_tensor, 76)\n",
        "print(torch.norm(batch_tensor - starting_image, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Q9fhmhc2QP"
      },
      "source": [
        "### Visualize the original and attacked images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otaK0LBxy_Nc"
      },
      "source": [
        "original_image = obtain_image(starting_image[0, :], do_normalize=True)\n",
        "attacked_image_tarantula = obtain_image(batch_tensor[0, :], do_normalize=True)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].set_title('Original image')\n",
        "axs[0].imshow(original_image)\n",
        "axs[1].set_title('Attacked image')\n",
        "axs[1].imshow(attacked_image_tarantula)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EPBTz506fDF"
      },
      "source": [
        "### Compute the updated probabilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHfl7w156bkt"
      },
      "source": [
        "output = model(batch_tensor)\n",
        "prob = output2prob(output)\n",
        "plot_top_classes(prob[0,:].data.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qj6D7UfbGjW"
      },
      "source": [
        "### Attack 2\n",
        "\n",
        "We will now update the image to make the model think this image is a **Tiger Cat (id 282)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhiwPiMabF6Z"
      },
      "source": [
        "model.eval()\n",
        "starting_image = prepare_image(img)\n",
        "batch_tensor = starting_image.clone()\n",
        "batch_tensor.requires_grad_(True)\n",
        "step = StepImage(starting_image, step_size=3, renorm=True)\n",
        "batch_tensor = generate_adversarial_example(model, batch_tensor, 282)\n",
        "print(torch.norm(batch_tensor - starting_image, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVCTDYe_bYBf"
      },
      "source": [
        "### Visualize the original and attacked images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7JPgYZzdDoO"
      },
      "source": [
        "original_image = obtain_image(starting_image[0, :], do_normalize=True)\n",
        "attacked_image_siamese = obtain_image(batch_tensor[0, :], do_normalize=True)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].set_title('Original image')\n",
        "axs[0].imshow(original_image)\n",
        "axs[1].set_title('Attacked image')\n",
        "axs[1].imshow(attacked_image_siamese)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY4C-CjGdBJm"
      },
      "source": [
        "### Compute the updated probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJsHpWKPbMSK"
      },
      "source": [
        "output = model(batch_tensor)\n",
        "prob = output2prob(output)\n",
        "plot_top_classes(prob[0,:].data.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0JKc0QEdcCt"
      },
      "source": [
        "### Compare Attack 1 & Attack 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0sBnS-xdcPq"
      },
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "axs[0].set_title('Original image')\n",
        "axs[0].imshow(original_image)\n",
        "axs[1].set_title('Attacked image 1')\n",
        "axs[1].imshow(attacked_image_tarantula)\n",
        "axs[2].set_title('Attacked image 2')\n",
        "axs[2].imshow(attacked_image_siamese)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mOyR2Ych3uH"
      },
      "source": [
        "Here we visualize both attacked images. Explain why the attacked image 2, comparing to the attacked image 1, looks more like the normal image?\n",
        "\n",
        "\\### Todo3\n",
        "\n",
        "Can you tell the difference between the adversarial examples and the original image? Briefly discuss why would this cause a security problem for deep neural network.\n",
        "\n",
        "\\###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raUVsO9k6_lV"
      },
      "source": [
        "### Maximizing layers\n",
        "Adversarial examples are generated by maximizing the log-probability of different classes. Let's try a different objective here. Typically we call the output from an intermediate layers as the embedding or feature map of the network. For instance, each layer of network generates a different embedding of the input image. Instead of maximizing one single probability, modify  a  random  image  to  minimize the l2-distance between its feature and the feature of the Corgi image. Try this with 3 different layers. \n",
        "\n",
        "Include the code below to extract the embedding of the layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8dBzJADpCV2"
      },
      "source": [
        "# This function creates a function that gives the output of a given\n",
        "# network at layer: layer_id.\n",
        "# Usage:\n",
        "# model_l = model_layer(model, layer_id_interest)\n",
        "# output_layer_interest = model_l(input)\n",
        "def model_layer(model, layer_id):\n",
        "  layers = [model.layer1, model.layer2, model.layer3, model.layer4]  \n",
        "  def forward(input):\n",
        "    layers_used = layers[:(layer_id+1)]\n",
        "    x = input\n",
        "    x = model.conv1(x)\n",
        "    x = model.bn1(x)\n",
        "    x = model.relu(x)\n",
        "    x = model.maxpool(x)\n",
        "    for l in layers_used:\n",
        "      x = l(x)\n",
        "    return x\n",
        "  return forward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxMnljtC7YaE"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "starting_image = torch.rand((1, 3, 224, 224))\n",
        "if cuda_available: starting_image = starting_image.cuda()\n",
        "batch_tensor = starting_image.clone().requires_grad_(True)\n",
        "step = StepImage(starting_image, step_size=0.05, renorm=False, norm_update='abs', is_normalized=False)\n",
        "\n",
        "### TODO4\n",
        "# Modify Layer ID (0-3) to select feature from different layers\n",
        "layer_id = \n",
        "###\n",
        "model_l = model_layer(model, layer_id)\n",
        "\n",
        "# target image and the embedding\n",
        "target_image = prepare_image(img)\n",
        "target_feat = model_l(target_image)\n",
        "\n",
        "for _ in tqdm(range(200)):\n",
        "  feat = model_l(batch_tensor)\n",
        "  ### TODO5     \n",
        "  # You should minimize the L2 norm between feat and target_feat\n",
        "  # Your code here:\n",
        "  loss = \n",
        "  ###\n",
        "  gradient, = torch.autograd.grad(loss, batch_tensor)\n",
        "  batch_tensor = step.step(batch_tensor, -gradient)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8QL9gZZ8GGr"
      },
      "source": [
        "original_image = obtain_image(starting_image[0, :], do_normalize=False)\n",
        "modified_image = obtain_image(batch_tensor[0, :], do_normalize=False)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].set_title('Original random image')\n",
        "axs[0].imshow(original_image)\n",
        "axs[1].set_title('Modified image')\n",
        "axs[1].imshow(modified_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSSfWN3NGUot"
      },
      "source": [
        "## Robust model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24BA6cCIqZWG"
      },
      "source": [
        "The property shown above is clearly not desirable. Creating such adversaries would allow to fool networks without humans noticing it, which could cause security issues amongst others. To address that, some researchers have proposed methods \\[1\\] for training robust models! Let's see what will happen if we attack the robust models:\n",
        "\n",
        "\\[1\\] [Image Synthesis with a Single (Robust) Classifier](https://arxiv.org/pdf/1906.09453.pdf), Santurkar et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgUEP0ojr0t7"
      },
      "source": [
        "### Download the robustly trained model and load it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I9Z3T3lXa-7"
      },
      "source": [
        "download('http://6.869.csail.mit.edu/fa19/psets19/pset6/imagenet_l2_3_0.pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0OgFQwfgEus"
      },
      "source": [
        "if cuda_available:\n",
        "  model_weights = torch.load('imagenet_l2_3_0.pt')\n",
        "else:\n",
        "  model_weights = torch.load('imagenet_l2_3_0.pt', map_location=torch.device('cpu'))\n",
        "model_weights_modified = {name.split('model.')[1]: value for name, value in model_weights['model'].items() if 'model' in name}\n",
        "model.load_state_dict(model_weights_modified)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL7_voVjsQ1Z"
      },
      "source": [
        "Here we show that the input image is modified to maximize the class **Tiger Cat** (id 282). Print the image and the udpated classification and inlude it in your report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy6YWnmeGkOH"
      },
      "source": [
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "initial_image = prepare_image(img, do_normalize=False)\n",
        "batch_tensor = initial_image.clone()\n",
        "batch_tensor.requires_grad_(True)\n",
        "step = StepImage(initial_image, step_size=2, renorm=True, is_normalized=False, eps=30)\n",
        "batch_tensor = generate_adversarial_example(model, batch_tensor, 282)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWm3NgrhHBPm"
      },
      "source": [
        "image = obtain_image(initial_image[0, :], do_normalize=False)\n",
        "plt.imshow(image)\n",
        "plt.figure()\n",
        "image = obtain_image(batch_tensor[0, :], do_normalize=False)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl_K-LTms7i0"
      },
      "source": [
        "### Compute the updated log-probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAHsAv8Qs7Gv"
      },
      "source": [
        "output = model(batch_tensor)\n",
        "prob = output2prob(output)\n",
        "plot_top_classes(prob[0,:].cpu().data.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI04SQQqtTpr"
      },
      "source": [
        "### \\### TODO6\n",
        "\n",
        "Include 2 more examples of the adversarial perturbations, targeted to a certain class, with the robust models. You can use the image provided or your new image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Repeat question 4.d with the robust model\n",
        "\n",
        "Not only adversarial example, robust model also change the resulted image when we try to infer the input from the embedding. Repeat all the procedure in question 4.d with the robust model. Does the results look different?"
      ],
      "metadata": {
        "id": "0CqBKJpqdlqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "starting_image = torch.rand((1, 3, 224, 224))\n",
        "if cuda_available: starting_image = starting_image.cuda()\n",
        "batch_tensor = starting_image.clone().requires_grad_(True)\n",
        "step = StepImage(starting_image, step_size=0.05, renorm=False, norm_update='abs', is_normalized=False)\n",
        "\n",
        "\n",
        "### TODO7\n",
        "# Modify Layer ID (0-3) to select feature from different layers\n",
        "layer_id = \n",
        "###\n",
        "model_l = model_layer(model, layer_id)\n",
        "\n",
        "# target image\n",
        "target_image = prepare_image(img)\n",
        "target_logit = model_l(target_image)\n",
        "\n",
        "for _ in tqdm(range(200)):\n",
        "  logit = model_l(batch_tensor)\n",
        "  ### TODO8     \n",
        "  # You should minimize the L2 norm between feat and target_feat\n",
        "  # Your code here: (can be copy from TODO5)\n",
        "  loss = \n",
        "  ###\n",
        "  gradient, = torch.autograd.grad(loss, batch_tensor)\n",
        "  batch_tensor = step.step(batch_tensor, -gradient)\n",
        "\n",
        "original_image = obtain_image(starting_image[0, :], do_normalize=False)\n",
        "modified_image = obtain_image(batch_tensor[0, :], do_normalize=False)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].set_title('Original random image')\n",
        "axs[0].imshow(original_image)\n",
        "axs[1].set_title('Modified image')\n",
        "axs[1].imshow(modified_image)"
      ],
      "metadata": {
        "id": "gaNQ-6vQf-Qf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}