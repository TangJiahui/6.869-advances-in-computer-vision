{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Pset3_6_869_sp22.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"HFj8s-8RT3vs"},"source":["%matplotlib inline\n","import numpy as np\n","from numpy.fft import fft2, ifft2, fftshift, ifftshift\n","from numpy import angle, real\n","from numpy import exp, abs, pi, sqrt\n","import matplotlib.pyplot as plt\n","import cv2\n","import scipy.ndimage as ndimage\n","\n","def imshow(im, cmap='gray'):\n","    # clip image from 0-1\n","    im = np.clip(im, 0, 1)\n","    plt.imshow(im, cmap=cmap)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"446yzZigT3vy"},"source":["! curl http://6.869.csail.mit.edu/sp21/pset3_data/einsteinandwho.jpg > einsteinandwho.jpg\n","! curl http://6.869.csail.mit.edu/sp21/pset3_data/bill.avi > bill.avi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7rQ_i992T3vz"},"source":["## Problem 1\n"]},{"cell_type":"code","metadata":{"id":"hXDTUMv4T3vz"},"source":["### TODO: ENTER YOUR CODE BELOW\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H_dWGhUET3vz"},"source":["## Problem 2\n"]},{"cell_type":"code","metadata":{"id":"o-vcClrcT3v0"},"source":["# scale image's intensity to [0,1] with mean value of 0.5 for better visualization.\n","def intensityscale(raw_img):\n","    \n","    # scale an image's intensity from [min, max] to [0, 1].\n","    v_min, v_max = raw_img.min(), raw_img.max()\n","    scaled_im = (raw_img * 1.0 - v_min) / (v_max - v_min)\n","    \n","    # keep the mean to be 0.5.\n","    meangray = np.mean(scaled_im)\n","    scaled_im = scaled_im - meangray + 0.5\n","    \n","    # clip to [0, 1]\n","    scaled_im = np.clip(scaled_im, 0, 1)\n","    \n","    return scaled_im\n","\n","\n","### ENTER YOUR CODE BELOW\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UlnuAmerT3v0"},"source":["## Problem 3.a"]},{"cell_type":"code","metadata":{"id":"KswSFrezT3v1"},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4;\n","\n","# horizontal movement from (0, 0) to (0, 1)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","\n","ff1 = fftshift(fft2(im1))\n","ff2 = fftshift(fft2(im2))\n","\n","plt.figure()\n","plt.subplot(121)\n","imshow(im1)\n","plt.subplot(122)\n","imshow(im2)\n","\n","plt.figure()\n","plt.subplot(121)\n","imshow(angle(ff1))\n","plt.subplot(122)\n","imshow(angle(ff2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q8wHgtdVT3v1"},"source":["### Magnify Change\n"]},{"cell_type":"code","metadata":{"id":"7VIdTa1hT3v1"},"source":["def magnifyChange(im1, im2, magnificationFactor):\n","    \n","    # find phase shift in frequency domain\n","    im1Dft = fft2(im1)\n","    im2Dft = fft2(im2)\n","    phaseShift = # TODO\n","\n","    # magnify the phase change in frequency domain\n","    magnifiedDft = # TODO\n","    \n","    # what does the magnified phase change cause in image space?\n","    magnified = ifft2(magnifiedDft).real;\n","    \n","    return magnified"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bjFLRGEuT3v2"},"source":["**HINT:** If you're not familiar with complex number in python, here's a quickstart."]},{"cell_type":"code","metadata":{"id":"x7I3wGemT3v2"},"source":["# create a complex number\n","x = 1 + 1j\n","print(\"x =\", x)\n","print(\"x.real\", x.real, \"x.imag\", x.imag)\n","\n","# magnitude and phase of complex number\n","mag = abs(x)\n","phase = angle(x)\n","\n","print(\"Magnitude\", mag)\n","print(\"Phase\", phase)\n","\n","# Euler's formula\n","y = mag * exp(phase * 1j)\n","print(\"y =\", y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6YWeepmT3v2"},"source":["# magnify position change\n","magnified = magnifyChange(im1, im2, magnificationFactor);\n","\n","plt.figure(figsize=(12,36))\n","plt.subplot(131)\n","imshow(im1); plt.title('im1');\n","\n","plt.subplot(132)\n","imshow(im2); plt.title('im2');\n","\n","plt.subplot(133)\n","imshow(magnified); plt.title('magnified');\n","plt.savefig(\"problem_3a.png\", bbox=\"tight\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2PCOffIUT3v2"},"source":["## Problem 3.b"]},{"cell_type":"code","metadata":{"id":"OLC6gSXMT3v3"},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4\n","\n","# horizontal movement from (1, 1) to (1, 2)\n","# additional vertical movement from (9, 9) to (8, 9)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","im1[8,8] = 1\n","im2[7,8] = 1\n","\n","\n","### TODO: ENTER YOUR CODE BELOW\n","### manually edit the expected matrix (currently set as zeros) by creating 1s to show the expected output\n","expected = np.zeros([imSize, imSize])\n","\n","\n","\n","# magnify position change\n","magnified = magnifyChange(im1, im2, magnificationFactor)\n","\n","\n","plt.figure(figsize=(12,36))\n","plt.subplot(141)\n","imshow(im1); plt.title('im1');\n","\n","plt.subplot(142)\n","imshow(im2); plt.title('im2');\n","\n","plt.subplot(143)\n","imshow(expected); plt.title('expected');\n","\n","plt.subplot(144)\n","imshow(magnified); plt.title('magnified');\n","plt.savefig(\"problem_3b.png\", bbox=\"tight\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VTP8LwLfT3v3"},"source":["## Problem 3.c"]},{"cell_type":"code","metadata":{"id":"YQs4fJZTT3v3"},"source":["# 9x9 images\n","imSize = 9\n","\n","# we would like to magnify the change between im1 and im2 by 4x\n","magnificationFactor = 4\n","\n","# width of our Gaussian window\n","sigma = 2\n","\n","# horizontal movement from (1, 1) to (1, 2)\n","# additional vertical movement from (9, 9) to (8, 9)\n","im1 = np.zeros([imSize, imSize])\n","im2 = np.zeros([imSize, imSize])\n","im1[0,0] = 1\n","im2[0,1] = 1\n","im1[8,8] = 1\n","im2[7,8] = 1\n","\n","# we will magnify windows of the image and aggregate the results\n","magnified = np.zeros([imSize, imSize])\n","\n","# meshgrid for computing Gaussian window\n","X, Y = np.meshgrid(np.arange(imSize), np.arange(imSize))\n","\n","for y in range(0, imSize, 2*sigma):\n","    for x in range(0, imSize, 2*sigma):\n","        gaussianMask = # TODO\n","        windowMagnified = magnifyChange(# TODO,\\\n","            magnificationFactor)\n","        magnified = magnified + windowMagnified\n","        \n","plt.figure(figsize=(12,36))\n","plt.subplot(131)\n","imshow(im1); plt.title('im1');\n","\n","plt.subplot(132)\n","imshow(im2); plt.title('im2');\n","\n","plt.subplot(133)\n","imshow(magnified); plt.title('magnified');\n","plt.savefig(\"problem_3c.png\", bbox=\"tight\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kj-KjWXBT3v3"},"source":["## Problem 3.d"]},{"cell_type":"code","metadata":{"id":"u7ISUwmbT3v4"},"source":["import numpy as np\n","import cv2\n","\n","cap = cv2.VideoCapture('bill.avi')\n","\n","# list of video frames\n","frames = []\n","\n","while(cap.isOpened()):\n","    # read frame from the video\n","    ret, frame = cap.read()\n","    \n","    if ret is False:\n","        break\n","        \n","    frames.append(frame)\n","\n","cap.release()\n","\n","# scale frame to 0-1\n","frames = np.array(frames) / 255.\n","print(\"frames size:\", frames.shape, \"# (nb_frames, height, width, channel)\")\n","\n","# get height, width\n","numFrames = frames.shape[0]\n","height = frames.shape[1]\n","width = frames.shape[2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hABCG47vT3v4"},"source":["### Motion magnification\n","Fill out code **here**"]},{"cell_type":"code","metadata":{"id":"8QTRy7waT3v4"},"source":["# 10x magnification of motion\n","magnificationFactor = 10\n","\n","# width of Gaussian window\n","sigma = 13\n","\n","# alpha for moving average\n","alpha = 0.5\n","\n","# we will magnify windows of the video and aggregate the results\n","magnified = np.zeros_like(frames)\n","\n","# meshgrid for computing Gaussian window\n","X, Y = np.meshgrid(np.arange(width), np.arange(height))\n","\n","# iterate over windows of the frames\n","xRange = list(range(0, width, 2*sigma))\n","yRange = list(range(0, height, 2*sigma))\n","numWindows = len(xRange) * len(yRange)\n","windowIndex = 1\n","\n","for y in yRange:\n","    for x in xRange:\n","        for channelIndex in range(3): # RGB channels\n","            for frameIndex in range(numFrames):\n","                \n","                # create windowed frames\n","                gaussianMask = # TODO\n","                windowedFrames = gaussianMask * frames[frameIndex,:,:,channelIndex]\n","            \n","                # initialize moving average of phase for current window/channel\n","                if frameIndex == 0:\n","                    windowAveragePhase = angle(fft2(windowedFrames))\n","                \n","                windowDft = fft2(windowedFrames)\n","                \n","                # compute phase shift and constrain to [-pi, pi] since\n","                # angle space wraps around\n","                windowPhaseShift = angle(windowDft) - windowAveragePhase\n","                windowPhaseShift[windowPhaseShift > pi] = windowPhaseShift[windowPhaseShift > pi] - 2 * pi\n","                windowPhaseShift[windowPhaseShift < -pi] = windowPhaseShift[windowPhaseShift < -pi] + 2 * pi\n","                \n","                # magnify phase shift\n","                windowMagnifiedPhase = # TODO\n","                 \n","                # go back to image space\n","                windowMagnifiedDft = # TODO\n","                windowMagnified = abs(ifft2(windowMagnifiedDft))\n","                \n","                # update moving average\n","                windowPhaseUnwrapped = windowAveragePhase + windowPhaseShift\n","                windowAveragePhase = alpha * windowAveragePhase + (1 - alpha) * windowPhaseUnwrapped\n","                \n","                # aggregate\n","                magnified[frameIndex,:,:,channelIndex] = magnified[frameIndex,:,:,channelIndex] + windowMagnified\n","        \n","        # print progress\n","        print('{}/{}'.format(windowIndex, numWindows), end='\\r')\n","        windowIndex += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zpBHydgKT3v6"},"source":["outputs = magnified / np.max(magnified)\n","for channelIndex in range(3):\n","    originalFrame = frames[0,:,:,channelIndex]\n","    magnifiedFrame = outputs[0,:,:,channelIndex]\n","    scale = np.std(originalFrame[:]) / np.std(magnifiedFrame[:])\n","    originalMean = np.mean(originalFrame[:])\n","    magnifiedMean = np.mean(magnifiedFrame[:])\n","    outputs[:,:,:,channelIndex] = magnifiedMean + scale * (outputs[:,:,:,channelIndex] - magnifiedMean)\n","\n","outputs = np.clip(outputs, 0, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ud60cXJqT3v7"},"source":["# create output video\n","fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n","# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('bill_magnified.avi',fourcc, 30.0, (height, width))\n","\n","for i in range(frames.shape[0]):\n","    # scale the frame back to 0-255\n","    frame = (np.clip(outputs[i], 0, 1) * 255).astype(np.uint8)\n","    \n","    # write frame to output video\n","    out.write(frame)\n","\n","out.release()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kpaXMWVOT3v7"},"source":["# Only for colab downloading videos\n","try:\n","    from google.colab import files\n","    files.download('bill_magnified.avi')\n","except:\n","    print(\"Only for google colab\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Problem 4: Eulerian Motion Magnification (6.869 Only)"],"metadata":{"id":"KavaF6GgjHuB"}},{"cell_type":"markdown","source":["Let's start by reading all the frames of the video."],"metadata":{"id":"4o2rAMM4VKDO"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","import scipy.signal as signal\n","import scipy.fftpack as fftpack\n","import matplotlib.pyplot as plt\n","\n","! curl http://people.csail.mit.edu/mrub/evm/video/baby.mp4 > baby.mp4\n","\n","cap = cv2.VideoCapture('baby.mp4')\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","# list of video frames\n","frames = []\n","\n","while(cap.isOpened()):\n","    # read frame from the video\n","    ret, frame = cap.read()\n","    \n","    if ret is False:\n","        break\n","    frame = cv2.resize(frame, (424, 240))\n","    frame = frame[:, 80:80+240]\n","    frames.append(frame)\n","\n","cap.release()\n","\n","# scale frame to 0-1\n","frames = np.array(frames) / 255.\n","print(\"frames size:\", frames.shape, \"# (nb_frames, height, width, channel)\")\n","\n","# get height, width\n","numFrames = frames.shape[0]\n","height = frames.shape[1]\n","width = frames.shape[2]\n","\n","# Helper function for displaying the pyramid\n","def display_pyramid(pyramid):\n","  N = len(pyramid)\n","  for lvl in range(len(pyramid)):\n","    plt.subplot(1, N, lvl+1)\n","    imshow(intensityscale(pyramid[lvl][0, ..., ::-1]))\n"],"metadata":{"id":"_ZMIQEZpjMp3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Problem 4a: Gaussian pyramid\n","We will first write a function to create a gaussian pyramid of the input frames. The function takes in a array of N frames (N, H, W, 3) and outputs a list of frames, each entry corresponding to the gaussian pyramid starting from the finest to the coarest.\n","\n"],"metadata":{"id":"OKLJq6EUVVO1"}},{"cell_type":"code","source":["def create_gaussian_pyramid(vid, num_levels=4):\n","  \n","  ### TODO: ENTER YOUR CODE BELOW\n","  ### return a list with the gaussian pyramid of the video.\n","  ### consider using the cv2.pyrDown function to create each level of the pyramid.\n","\n","  return [] # returning empty list for now. Change this!"],"metadata":{"id":"e2n7QwvsjOIu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gaussian_pyramid = create_gaussian_pyramid(frames)"],"metadata":{"id":"Ie6ISraikr83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display_pyramid(gaussian_pyramid)\n","plt.savefig(\"gaussian_pyramid.png\", bbox_inches=\"tight\")"],"metadata":{"id":"OnV6AqTRm9ml"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Problem 4b: Laplacian pyramid\n","Now let's make the Laplacian pyramid using the gaussian pyramids you produced in 4a.\n"],"metadata":{"id":"C7H1kVifjYLV"}},{"cell_type":"code","source":["def create_laplacian_pyramid(gaussian_pyramid):\n","  ### TODO: ENTER YOUR CODE BELOW\n","  ### use the gaussian pyramid to create the laplacian pyramid for the video.\n","  ### You might find cv2.pyrUp function useful.\n","\n","  return [] # returning empty list for now. Change this!"],"metadata":{"id":"n3PqHqmsk0fa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["laplacian_pyramid = create_laplacian_pyramid(gaussian_pyramid)"],"metadata":{"id":"HAXHU1OmT9I0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display_pyramid(laplacian_pyramid)\n","plt.savefig(\"laplacian_pyramid.png\", bbox_inches=\"tight\")"],"metadata":{"id":"j9XcjPUmkswA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Problem 4c: Butter bandpass filter temporally"],"metadata":{"id":"T-LEl3GheDXT"}},{"cell_type":"code","source":["def butter_bandpass_filter(laplace_video, low_freq, high_freq, fs, filter_order=5):\n","    omega = 0.5 * fs\n","    low = low_freq / omega\n","    high = high_freq / omega\n","\n","    # create a \"bandpass\" signal filter using the signal.butter function\n","    b, a = # TODO\n","    \n","\n","    # filter the laplcian of the video using the signal.lfilter\n","    y = # TODO \n","    \n","    return y\n","\n","amplification = 20\n","low = 0.4\n","high = 3.\n","\n","bandpass_filtered = []\n","for i in range(len(laplacian_pyramid)):\n","    # Applying the butter_bandpass_filter to each of \n","    # the levels of the laplacian pyramid\n","    \n","    filter = butter_bandpass_filter(laplacian_pyramid[i], low, high, fps)\n","    filter *= amplification\n","    bandpass_filtered.append(filter)"],"metadata":{"id":"_CA92pT1k4Uh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Problem 4d: Combining the amplified filtered signal to get the magnified video"],"metadata":{"id":"PQJj8lAmlllR"}},{"cell_type":"code","source":["### TODO: ENTER YOUR CODE BELOW\n","### Combine all the bandpassed filtered signals to one matrix which is the same \n","### dimensions as the input video. \n","### Hint: start from the lowest resolution of the amplified filtered signal, \n","### upsample that using cv2.pyrUp and add it to the amplified filtered signal \n","### at the next higher resolution.\n","\n","### The output video, 'euler_magnified_video', will be the \n","### input video frames + combined magnified signal.\n"],"metadata":{"id":"-NUOKtD6lWhP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create output video\n","fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n","# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('baby_euler_magnification.avi', fourcc, 30.0, (height, width))\n","\n","for i in range(frames.shape[0]):\n","    # scale the frame back to 0-255\n","    frame = (np.clip(euler_magnified_video[i], 0, 1) * 255).astype(np.uint8)\n","    \n","    # write frame to output video\n","    out.write(frame)\n","\n","out.release()"],"metadata":{"id":"umO73vIvfH2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"-kCdDPBmlFmN"},"execution_count":null,"outputs":[]}]}